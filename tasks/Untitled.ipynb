{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to automatically reload modules who's content has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funbo as fb\n",
    "import funbo.plotting as fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_bounds = [('x', 0, 10)]\n",
    "range_bounds = (-5, 5)\n",
    "\n",
    "def make_objective(to_fit, sample_num, sample_dist):\n",
    "    def objective(f):\n",
    "        _, xmin, xmax = domain_bounds[0]\n",
    "        # global reward\n",
    "        R_g = fp.integrate(lambda x: (f(x) - to_fit(x))**2, (xmin, xmax))\n",
    "        # local rewards\n",
    "        R_ls = []\n",
    "        if sample_dist == 'linear':\n",
    "            reward_xs = np.linspace(xmin, xmax, num=sample_num)\n",
    "        elif sample_dist == 'random':\n",
    "            reward_xs = np.random.uniform(xmin, xmax, size=(sample_num,))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        for x in reward_xs:\n",
    "            R_l = (f(x)-to_fit(x))**2\n",
    "            R_ls.append((x, R_l))\n",
    "        return R_ls, R_g\n",
    "    return objective\n",
    "\n",
    "def to_fit(x):\n",
    "    return np.sin(x) * 2*np.cos(x/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator(fb.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        c = fb.GPPriorSelectConfig(self.optimiser)\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fb.BayesSelectConfig(self.optimiser)\n",
    "        c.extraction_config.aux_optimiser_params['exact_gradient'] = False\n",
    "        c.extraction_config.tracking_l = 10\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "objective = make_objective(to_fit, 10, 'linear')\n",
    "opt = fb.Optimiser(objective, domain_bounds, range_bounds, desired_extremum='min')\n",
    "opt.run(Coordinator(opt, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 8))\n",
    "fp.plot_convergence(opt, best_R_g=0, ax=ax1)\n",
    "fp.plot_consecutive_distance(opt, ax=ax2)\n",
    "fp.plot_timings(opt, ax=ax3)\n",
    "fig.tight_layout()\n",
    "\n",
    "fp.plot_trials(opt, opt.trials, to_fit, color_by_reward=True)\n",
    "fp.plot_surrogate_with_trials(opt, -1, to_fit)\n",
    "\n",
    "inc_i, inc = opt.get_incumbent()\n",
    "print('incumbent = trial {}'.format(inc_i))\n",
    "fp.plot_trial_area(opt, inc, to_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
