{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments to show the effect of querying a GP one point at a time or all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to automatically reload modules who's content has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funbo as fb\n",
    "import funbo.plotting as fp\n",
    "import distributed_gp as dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleFunction1D:\n",
    "    def __init__(self, noise, num_samples, x_range, exclude_ranges, predict_num):\n",
    "        self.noise = noise\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.xmin, self.xmax = x_range\n",
    "        X = np.random.uniform(self.xmin, self.xmax, size=(num_samples, 1))\n",
    "        if exclude_ranges is not None:\n",
    "            cond = np.logical_not(np.logical_or.reduce([np.logical_and(a < X, X < b) for a, b in exclude_ranges]))\n",
    "            X = X[np.where(cond)].reshape(-1, 1)\n",
    "        self.X = X\n",
    "        self.y = self.__call__(X)\n",
    "        self.xs = np.linspace(self.xmin, self.xmax, num=predict_num)\n",
    "        self.ys = self.__call__(self.xs, apply_noise=False)\n",
    "\n",
    "    def __call__(self, x, apply_noise=True):\n",
    "        v = np.sin(x*2) * 0.2*x**2 + 4*np.cos(x)\n",
    "        if apply_noise and self.noise != 0:\n",
    "            v += np.random.normal(loc=0, scale=self.noise, size=np.asarray(x).shape)\n",
    "        return v\n",
    "\n",
    "    def plot(self, ax=None, show_data_points=True):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(20, 8))\n",
    "        ax.plot(self.xs, self.ys, '--', color='grey')\n",
    "        if show_data_points:\n",
    "            ax.scatter(self.X, self.y, marker='.', color='blue', alpha=0.2, zorder=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ExampleFunction1D(noise=2, num_samples=1000, x_range=(0, 10), exclude_ranges=None, predict_num=100)\n",
    "f.plot(show_data_points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query(model, f, n, batch_size, repeats=5, gradient=False):\n",
    "    np.random.seed(0)\n",
    "    X = np.random.uniform(f.xmin, f.xmax, size=(n, 1))\n",
    "    xs = np.array_split(X, n//batch_size)\n",
    "    t = fb.utils.Timer()\n",
    "    for i in range(repeats):\n",
    "        for x in xs:\n",
    "            if gradient:\n",
    "                model.predict_gradients(x)\n",
    "            else:\n",
    "                model.predict(x)\n",
    "        print('{}/{}'.format(i+1, repeats))\n",
    "    return t.stop()/repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(sizes, times, n):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    fig.suptitle('The effect of batch size when querying at {} points'.format(n))\n",
    "    \n",
    "    ax1.bar(np.arange(len(times)), np.array(times)/n*1000, tick_label=[str(s) for s in sizes])\n",
    "    ax1.set_ylabel('computation time per point (ms)')\n",
    "    ax2.set_xlabel('batch size')\n",
    "\n",
    "    ax2.plot(sizes, np.array(times)/n*1000, 'o-')\n",
    "    ax2.set_ylabel('computation time per point (ms)')\n",
    "    ax2.set_xlabel('batch size')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fb.GPySurrogate(\n",
    "    init_params=dict(\n",
    "        kernel=GPy.kern.RBF(input_dim=1, ARD=False),\n",
    "        normalizer=True\n",
    "    ), optimise_params=dict(\n",
    "        num_restarts=1\n",
    "))\n",
    "t = fb.utils.Timer()\n",
    "np.random.seed(0)\n",
    "model.fit(f.X, f.y, initial_hyper_params=None)\n",
    "print('fit in {}'.format(t.stop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "sizes = (1, 2, 10, 100, 200, 500, 1000, 4000, 8000, 10_000)\n",
    "#sizes = (1, 10_000)\n",
    "times = []\n",
    "for batch_size in sizes:\n",
    "    time = test_query(model, f, n, batch_size, gradient=False)\n",
    "    print('batch size {}: {:.3f} seconds'.format(batch_size, time))\n",
    "    times.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(sizes, times, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst, best = np.argmax(times), np.argmin(times)\n",
    "print('sampling in batches of {} is {} times faster than batches of {}'.format(sizes[best], times[worst]/times[best], sizes[worst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = 10_000\n",
    "f_time = test_query(model, f, n2, n2, gradient=False)\n",
    "grad_time = test_query(model, f, n2, n2, gradient=True)\n",
    "print('computing the function is {}x faster than computing the gradient'.format(grad_time/f_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _():\n",
    "    from scipy.optimize import approx_fprime\n",
    "    \n",
    "    def derivative(func):\n",
    "        def df(X):\n",
    "            dfs = []\n",
    "            f = lambda x: np.asscalar(func(np.array([x])))\n",
    "            for x in X:\n",
    "                dfs.append(approx_fprime(x, f, epsilon=np.sqrt(np.finfo(float).eps)))\n",
    "            return np.array(dfs).reshape(-1, 1)\n",
    "        return df\n",
    "    \n",
    "    eval_count = [0] # must be mutable, so use list\n",
    "    def f(x):\n",
    "        print(x)\n",
    "        eval_count[0] += x.shape[0]\n",
    "        return np.array(1)\n",
    "    df = derivative(f)\n",
    "    df(np.array([[0,1,2,5,6]]))\n",
    "    print(eval_count)\n",
    "_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to approximate the gradient at x in D dimensions requires D+1 evaluations, one at x and D more at x + pertubation in each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Realistic Scenario (using real optimisation data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_bounds = [('x1', 0, 6), ('x2', 0, 6)]\n",
    "range_bounds = (-1, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy=False\n",
    "def to_fit(X):\n",
    "    ''' from https://github.com/fmfn/BayesianOptimization/issues/18 '''\n",
    "    x, y = X[:,0], X[:,1]\n",
    "    a = np.exp(-( (x - 2)**2/0.7 + (y - 4)**2/1.2) + (x - 2)*(y - 4)/1.6 )\n",
    "    b = np.exp(-( (x - 4)**2/3 + (y - 2)**2/2.) )\n",
    "    c = np.exp(-( (x - 4)**2/0.5 + (y - 4)**2/0.5) + (x - 4)*(y - 4)/0.5 )\n",
    "    d = np.sin(3.1415 * x)\n",
    "    e = np.exp(-( (x - 5.5)**2/0.5 + (y - 5.5)**2/.5) )\n",
    "    val = 2*a + b - c + 0.17 * d + 2*e\n",
    "    if noisy:\n",
    "        val += np.random.normal(0, 0.2, size=None if isinstance(x, float) else x.shape)\n",
    "    #return val.reshape(-1, 1)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objective(to_fit, sample_num):\n",
    "    def objective(f):\n",
    "        bounds = [b[1:] for b in domain_bounds]\n",
    "        R_g = 0.0\n",
    "        def g(x):\n",
    "            return (f(x) - to_fit(x))**2\n",
    "        # local rewards\n",
    "        R_ls = []\n",
    "        print('calculating the local rewards')\n",
    "        for x in fb.utils.RegularGrid(sample_num, bounds):\n",
    "            R_l = g(x)\n",
    "            R_ls.append((x, R_l))\n",
    "            R_g += R_l\n",
    "        return R_ls, R_g\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator(fb.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        #c = fb.GPPriorSelectConfig(self.optimiser)\n",
    "        c = fb.RandomCPSelectConfig(self.optimiser)\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fb.BayesSelectConfig(self.optimiser)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "objective = make_objective(to_fit, sample_num=15)\n",
    "opt = fb.Optimiser(objective, domain_bounds, range_bounds, desired_extremum='min')\n",
    "opt.run(Coordinator(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = opt.get_training_data(fb.BayesSelectConfig(opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: do same timing tests using the dataset gathered above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
