{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to automatically reload modules who's content has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function_bo as fbo\n",
    "from function_bo_plotting import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions import Activations, WeightedBasisFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_bounds = ('x', 0, 10)\n",
    "range_bounds = (-5, 5)\n",
    "\n",
    "class Coordinator(fbo.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        c = fbo.GPPriorSelectConfig(self.domain_bounds)\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fbo.BayesSelectConfig(self.domain_bounds)\n",
    "        c.tracking_l = 10\n",
    "        return c\n",
    "\n",
    "\n",
    "def make_objective(to_fit, sample_num, sample_dist):\n",
    "    def objective(f):\n",
    "        _, xmin, xmax = domain_bounds\n",
    "        # global reward\n",
    "        R_g = integrate(lambda x: (f(x) - to_fit(x))**2, (xmin, xmax))\n",
    "        # local rewards\n",
    "        R_ls = []\n",
    "        if sample_dist == 'linear':\n",
    "            reward_xs = np.linspace(xmin, xmax, num=sample_num)\n",
    "        elif sample_dist == 'random':\n",
    "            reward_xs = np.random.uniform(xmin, xmax, size=(sample_num,))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        for x in reward_xs:\n",
    "            R_l = (f(x)-to_fit(x))**2\n",
    "            R_ls.append((x, R_l))\n",
    "        return R_ls, R_g\n",
    "    return objective\n",
    "\n",
    "# set this global after each optimisation\n",
    "op = None\n",
    "\n",
    "def test_approx_function(to_fit, coordinator, objective=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        to_fit: the function to approximate\n",
    "        trials: (pre_phase_trials, max_trials)\n",
    "    \"\"\"\n",
    "    if objective is None:\n",
    "        objective = make_objective(to_fit, 10, 'linear')\n",
    "\n",
    "    np.random.seed(0)\n",
    "    opt = fbo.Optimiser(objective, domain_bounds, range_bounds, desired_extremum='min', coordinator=coordinator)\n",
    "    opt.run()\n",
    "    plot_convergence(opt, best_R_g=0)\n",
    "    plot_trials(opt, opt.trials, to_fit, color_by_reward=True)\n",
    "    plot_surrogate_with_trials(opt, -1, to_fit)\n",
    "    \n",
    "    inc_i, inc = opt.get_incumbent()\n",
    "    print('incumbent = trial {}'.format(inc_i))\n",
    "    plot_trial_area(opt, inc, to_fit)\n",
    "    \n",
    "    global op\n",
    "    op = opt\n",
    "\n",
    "def plot_to_fit(to_fit):\n",
    "    _, xmin, xmax = domain_bounds\n",
    "    xs = np.linspace(xmin, xmax, num=100)\n",
    "    plt.plot(xs, [to_fit(x) for x in xs], 'k--', label='to fit')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fit(x):\n",
    "    return np.sin(x) * 2*np.cos(x/4)\n",
    "plot_to_fit(to_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fitting a simple function with a single attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approx_function(to_fit, Coordinator(domain_bounds, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fitting a simple function with a two attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approx_function(to_fit, Coordinator(domain_bounds, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surrogate_3D(op, op.trials[-1].surrogate, flip_z=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test fitting with only a single random sample in the pre-phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = test_approx_function(to_fit,  Coordinator(domain_bounds, 1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise a noisy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fit_noisy(x):\n",
    "    size = x.size if isinstance(x, np.ndarray) else None\n",
    "    return to_fit(x) + np.random.normal(loc=0, scale=0.2, size=size)\n",
    "\n",
    "plt.subplots(figsize=(16,8))\n",
    "plot_to_fit(to_fit_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approx_function(to_fit_noisy, Coordinator(domain_bounds, 4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surrogate_3D(op, op.trials[-4].surrogate, flip_z=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a function which has flat regions and more intricate detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = WeightedBasisFunctions(arguments=[(2, 2, 1, 6), (6, 1, 1, 1), (8, 1, 2, 2)], # center, width, weight, power\n",
    "                               functions=Activations.super_Gaussian)\n",
    "def plot_super_gaussian():\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    _, xmin, xmax = domain_bounds\n",
    "    xs = np.linspace(xmin, xmax, num=200)\n",
    "    f.plot(ax, xs, color='r', show_basis=False, label='Super Gaussian')\n",
    "plot_super_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_approx_function(f, Coordinator(domain_bounds, 10, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample R_l more frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, xmin, xmax = domain_bounds\n",
    "objective = make_objective(f, 20, 'linear')\n",
    "\n",
    "class Coordinator2(fbo.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        c = fbo.GPPriorSelectConfig(self.domain_bounds)\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fbo.BayesSelectConfig(self.domain_bounds)\n",
    "        c.surrogate_model_params = dict(\n",
    "            kernel=GPy.kern.RBF(input_dim=2, ARD=True),\n",
    "            normalizer=True\n",
    "        )\n",
    "        c.tracking_l = 10\n",
    "        return c\n",
    "\n",
    "test_approx_function(f, Coordinator2(domain_bounds, 5, 10), objective=objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surrogate_3D(op, op.trials[-4].surrogate, flip_z=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling even more frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, xmin, xmax = domain_bounds\n",
    "objective = make_objective(f, 40, 'linear')\n",
    "\n",
    "class CoordinatorSparse(fbo.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        c = fbo.GPPriorSelectConfig(self.domain_bounds)\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fbo.BayesSelectConfig(self.domain_bounds)\n",
    "        c.surrogate_class = GPy.models.SparseGPRegression\n",
    "        c.surrogate_model_params = dict(\n",
    "            kernel = GPy.kern.RBF(input_dim=2),\n",
    "            num_inducing=20,\n",
    "            normalizer=True\n",
    "        )\n",
    "        c.surrogate_optimise_params = dict(\n",
    "            parallel = False, # Can't use parallel optimisation with sparse GP (bug)\n",
    "            verbose = True,\n",
    "            num_restarts = 1\n",
    "        )\n",
    "        c.tracking_l = 10\n",
    "        return c\n",
    "\n",
    "test_approx_function(f, CoordinatorSparse(domain_bounds, 10, 20), objective=objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the effect of sampling R_l at different places each trial\n",
    "Also in the pre_phase the sampled functions are engineered to hopefully be more representative of the function to fit (non-zero mean and variance > 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, xmin, xmax = domain_bounds\n",
    "objective = make_objective(f, 10, 'random')\n",
    "\n",
    "class Coordinator3(fbo.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        c = fbo.GPPriorSelectConfig(self.domain_bounds)\n",
    "        c.mu = lambda x: 1.0 # bias\n",
    "        c.kernel = GPy.kern.RBF(input_dim=1, variance=1.5, lengthscale=1.0) # TODO: not multi-dimensional\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fbo.BayesSelectConfig(self.domain_bounds)\n",
    "        return c\n",
    "\n",
    "test_approx_function(f, Coordinator3(domain_bounds, 10, 15), objective=objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surrogate_3D(op, op.trials[-4].surrogate, flip_z=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
