{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to automatically reload modules who's content has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funbo as fb\n",
    "import funbo.plotting as fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulated_annealing as sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A function fitting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_bounds = [(0, 6), (0, 7)]\n",
    "range_bounds = (-1, 2.5)\n",
    "def to_fit(X):\n",
    "    ''' from https://github.com/fmfn/BayesianOptimization/issues/18 '''\n",
    "    x, y = X[:,0], X[:,1]\n",
    "    a = np.exp(-( (x - 2)**2/0.7 + (y - 4)**2/1.2) + (x - 2)*(y - 4)/1.6 )\n",
    "    b = np.exp(-( (x - 4)**2/3 + (y - 2)**2/2.) )\n",
    "    c = np.exp(-( (x - 4)**2/0.5 + (y - 4)**2/0.5) + (x - 4)*(y - 4)/0.5 )\n",
    "    d = np.sin(3.1415 * x)\n",
    "    e = np.exp(-( (x - 5.5)**2/0.5 + (y - 5.5)**2/.5) )\n",
    "    val = 2*a + b - c + 0.17 * d + 2*e\n",
    "    #return val.reshape(-1, 1)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimisation(net, state_record, num_frames, show_to_fit=False, frame_duration=200, display=True, interactive=False):\n",
    "    g = fb.RegularGrid(50, domain_bounds, traverse_order='big')\n",
    "    X, Y = g.meshgrid(cartesian_index=False)\n",
    "    Z = g.fun_on_grid(to_fit)\n",
    "    goal_XYZ = (X, Y, Z)\n",
    "    if not show_to_fit:\n",
    "        goal_XYZ = None\n",
    "    \n",
    "    num_frames = num_frames\n",
    "    amplitudes = [a for i, a in enumerate(state_record) if i % (len(state_record)//num_frames) == 0]\n",
    "    args = dict(\n",
    "        net=net,\n",
    "        amplitudes=amplitudes,\n",
    "        goal_XYZ=goal_XYZ,\n",
    "        axes_names=('x1', 'x2', 'y'),\n",
    "        axes_limits=(*domain_bounds, range_bounds),\n",
    "    )\n",
    "    if interactive:\n",
    "        sa.plot_elastic_net_animation_interactive(**args)\n",
    "    else:\n",
    "        return sa.plot_elastic_net_animation(**args, frame_duration=frame_duration, display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_simulated_annealing(h):\n",
    "    np.random.seed(0)\n",
    "    grid = fb.RegularGrid(num_values=h.num_CP, bounds=domain_bounds)\n",
    "    net = fb.ElasticNet(grid, elastic_stiffness=h.elastic_stiffness, range_bounds=range_bounds)\n",
    "    fit_cost = lambda net, amplitudes: np.zeros(shape=net.grid.shape)\n",
    "    def perturbation(step_size):\n",
    "        return np.random.uniform(-step_size, step_size, size=grid.shape)\n",
    "    candidate_func = lambda current_amplitudes: np.clip(current_amplitudes + perturbation(h.initial_step), *net.range_bounds)\n",
    "    cooling_schedule = lambda i: sa.temperature_exponential_decay(i, M=h.M, factor=h.factor, T_0=h.T_0, T_min=h.T_min)\n",
    "    best_a, best_E, state_record, acceptance_record = sa.elastic_net_simulated_annealing(net, fit_cost, initial_amplitudes=net.random_amplitudes(),\n",
    "                                                                                         max_its=h.max_its, CP_batch_size=h.CP_batch_size,\n",
    "                                                                                         candidate_func=candidate_func, cooling_schedule=cooling_schedule)\n",
    "    print('acceptance rate = {}'.format(np.count_nonzero(acceptance_record)/acceptance_record.size))\n",
    "    print('best E = {}'.format(best_E))\n",
    "    return net, best_a, state_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyper_params:\n",
    "    max_its=100\n",
    "    \n",
    "    initial_step=0.3 # not adjustable yet\n",
    "    #step_alter_chunk=10\n",
    "    \n",
    "    M=1 # lower seems to be more reliably good\n",
    "    factor=0.8\n",
    "    T_0=1\n",
    "    T_min=0.2\n",
    "\n",
    "    CP_batch_size=1\n",
    "    \n",
    "    num_CP=10\n",
    "    elastic_stiffness=1\n",
    "\n",
    "net, best_a, state_record = optimise_simulated_annealing(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_optimisation(net, [a for a, e in state_record], num_frames=30)\n",
    "ani = plot_optimisation(net, [a for a, e in state_record], num_frames=20, display=False)\n",
    "sa.display_video(ani)\n",
    "plt.close()\n",
    "#sa.save_video(ani, 'simulated_annealing_elastic.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _():\n",
    "    g = fb.RegularGrid(50, domain_bounds, traverse_order='big')\n",
    "    X, Y = g.meshgrid(cartesian_index=False)\n",
    "    Z = g.fun_on_grid(to_fit)\n",
    "    goal_XYZ = (X, Y, Z)\n",
    "    goal_XYZ = None\n",
    "    \n",
    "    sa.plot_elastic_net(net, amplitudes=best_a, goal_XYZ=goal_XYZ, axes_names=('x1', 'x2', 'y'), axes_limits=(*domain_bounds, range_bounds))\n",
    "_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    xs = np.arange(len(state_record))\n",
    "    ax.plot(xs, [e for _, e in state_record])\n",
    "    ax.set_ylabel('E')\n",
    "    ax.set_xlabel('iteration')\n",
    "_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _():\n",
    "    g = fb.RegularGrid(50, domain_bounds, traverse_order='big')\n",
    "    X, Y = g.meshgrid(cartesian_index=False)\n",
    "    Z = g.fun_on_grid(to_fit)\n",
    "    goal_XYZ = (X, Y, Z)\n",
    "    #goal_XYZ = None\n",
    "    \n",
    "    \n",
    "    #sa.plot_elastic_net(g, net, amplitude=net.random_amplitudes(), goal_z=Z, axes_names=('x1', 'x2', 'y'))\n",
    "    \n",
    "    \"\"\"\n",
    "    amplitudes = []\n",
    "    for i in range(4):\n",
    "        amplitudes.append(net.random_amplitudes())\n",
    "    \"\"\"\n",
    "    \n",
    "    num_frames = 20\n",
    "    amplitudes = [a for i, (a, e) in enumerate(state_record) if i % (len(state_record)//num_frames) == 0]\n",
    "    sa.plot_elastic_net_animation_interactive(net, amplitudes=amplitudes, goal_XYZ=goal_XYZ, axes_names=('x1', 'x2', 'y'), axes_limits=(*domain_bounds, range_bounds))\n",
    "_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Advantages over Simulated Annealing:\n",
    "- less hyperparameters\n",
    "- less sensitive to hyperparameter settings (adagrad)\n",
    "- more accurate result\n",
    "- faster to converge to a decent solution\n",
    "\n",
    "Disadvantages over simulated annealing:\n",
    "- local search rather than global search\n",
    "- requires gradient calculation which is more expensive than value calculation for GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_GD(h):\n",
    "    np.random.seed(0)\n",
    "    grid = fb.RegularGrid(num_values=h.num_CP, bounds=domain_bounds)\n",
    "    net = fb.ElasticNet(grid, elastic_stiffness=h.elastic_stiffness, range_bounds=range_bounds)\n",
    "    if h.fit_to_func:\n",
    "        Z = grid.fun_on_grid(to_fit)\n",
    "        fit_cost_gradient = lambda amplitudes: amplitudes - Z # -(Z - amplitudes)\n",
    "    else:\n",
    "        fit_cost_gradient = lambda amplitudes: np.zeros(shape=net.grid.shape)\n",
    "    cost_gradient = lambda state: fit_cost_gradient(state) + net.elastic_potentials_gradient(state)\n",
    "    state, state_record = fb.gradient_descent(cost_gradient, initial_state=net.random_amplitudes(), max_its=h.max_its, step_size=h.step_size, adaptive=h.adaptive, record_state=True)\n",
    "    return net, state, state_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyper_params:\n",
    "    max_its = 100\n",
    "    adaptive = False\n",
    "    step_size = lambda i: 0.1\n",
    "    \n",
    "    num_CP=20\n",
    "    elastic_stiffness=1\n",
    "    fit_to_func=False\n",
    "\n",
    "net, state, state_record = optimise_GD(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_optimisation(net, state_record, show_to_fit=True, num_frames=10, interactive=True)\n",
    "ani = plot_optimisation(net, state_record, num_frames=20, display=False)\n",
    "sa.display_video(ani)\n",
    "plt.close()\n",
    "#sa.save_video(ani, 'gradient_descent_elastic.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyper_params:\n",
    "    max_its = 100\n",
    "    adaptive = True\n",
    "    step_size = lambda i: 1\n",
    "    num_CP=20\n",
    "    elastic_stiffness=1\n",
    "    fit_to_func=False\n",
    "\n",
    "net, state, state_record = optimise_GD(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_optimisation(net, state_record, num_frames=30)\n",
    "ani = plot_optimisation(net, state_record, num_frames=20, display=False)\n",
    "sa.display_video(ani)\n",
    "plt.close()\n",
    "#sa.save_video(ani, 'adagrad_elastic.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimisation(net, state_record, num_frames=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyper_params:\n",
    "    max_its = 20\n",
    "    adaptive = True\n",
    "    step_size = lambda i: 1\n",
    "    \n",
    "    num_CP=20\n",
    "    elastic_stiffness=0.01\n",
    "    fit_to_func=True\n",
    "\n",
    "net, state, state_record = optimise_GD(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimisation(net, state_record, show_to_fit=True, num_frames=20, interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
