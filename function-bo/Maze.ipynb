{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to automatically reload modules who's content has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# configure matplotlib\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import GPy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function_bo as fbo\n",
    "from function_bo_plotting import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = maze.Simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_bounds = ('h', 0, 1) # y-position (height)\n",
    "range_bounds = (0, 1)   # x-position\n",
    "\n",
    "world_num = 2\n",
    "\n",
    "def objective(f):\n",
    "    def control(height):\n",
    "        return f(height/sim.h)*sim.w\n",
    "    R_g, trail = sim.run(fps=400, ball_control=control, quiet=True, world_num=world_num)\n",
    "    reached_h = (sim.h-trail[-1][1])/sim.h\n",
    "    print(reached_h)\n",
    "    _, xmin, xmax = domain_bounds\n",
    "    reward_hs = np.linspace(xmin, xmax, num=40)\n",
    "    #TODO: idea, reward for staying close to the center?\n",
    "    \n",
    "    # need to reward for surviving and also important is to inform the surrogate where the bad regions are\n",
    "    # and so negative examples have to be added\n",
    "    R_ls = []\n",
    "    for h in reward_hs:\n",
    "        if h > reached_h:\n",
    "            break\n",
    "        R_ls.append((h, 1.0))\n",
    "    if h != reward_hs[-1]:\n",
    "        R_ls.append((h, 0.0))\n",
    "    return R_ls, R_g\n",
    "\n",
    "def plot_walls(ax):\n",
    "    world = sim.get_world(world_num)\n",
    "    for wall in world:\n",
    "        r = wall.rect\n",
    "        x, y, w, h = r.x/sim.w, 1-r.y/sim.h, r.w/sim.w, -r.h/sim.h\n",
    "        rect = mpl.patches.Rectangle((y, x), h, w, facecolor='green', alpha=0.4)\n",
    "        ax.add_patch(rect)\n",
    "    for y in (0,1):\n",
    "        ax.axhline(y=y, linestyle='--', color='green', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator(fbo.Coordinator):\n",
    "    def get_pre_phase_config(self, trial_num):\n",
    "        c = fbo.RandomSelectConfig(self.domain_bounds)\n",
    "        #c.mu = lambda x: 0.5 # bias\n",
    "        #c.kernel = GPy.kern.RBF(input_dim=1, variance=0.1, lengthscale=0.15)\n",
    "        return c\n",
    "\n",
    "    def get_bayes_config(self, trial_num):\n",
    "        c = fbo.BayesSelectConfig(self.domain_bounds)\n",
    "        c.surrogate_model_params = dict(\n",
    "            kernel = GPy.kern.RBF(input_dim=2, ARD=False)\n",
    "        )\n",
    "        c.surrogate_optimise_params = dict(\n",
    "            num_restarts = 4,\n",
    "            parallel = True,\n",
    "            verbose = True\n",
    "        )\n",
    "        c.tracking_l = 0.4\n",
    "        return c\n",
    "    \n",
    "coordinator = Coordinator(domain_bounds, 20, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "op = fbo.Optimiser(objective, domain_bounds, range_bounds, desired_extremum='max', coordinator=coordinator)\n",
    "op.run()\n",
    "plot_convergence(op, best_R_g=sim.h)\n",
    "plot_trials(op, op.trials, color_by_reward=True)\n",
    "fig = plot_surrogate_with_trials(op, -1)\n",
    "plot_walls(fig.axes[0])\n",
    "\n",
    "inc_i, inc = op.get_incumbent()\n",
    "print('incumbent = trial {}'.format(inc_i))\n",
    "plot_trials(op, [inc], color_by_reward=True)\n",
    "#plot_trial_area(op, inc, to_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trials(op, op.trials, color_by_reward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surrogate_with_trials(op, -1)\n",
    "plot_walls(fig.axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surrogate_3D(op, op.trials[-1].surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
